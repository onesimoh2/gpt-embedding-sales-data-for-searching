{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me one of the products I bought last\n",
      "One of the products you bought last was \"Tape dispenser (Black)\" on 5/27/2016. You purchased 50 units at a price of $1600.\n",
      "Tell me the other product I boght\n",
      "Another product you bought was \"10 mm Double sided bubble wrap 20m\" on 5/27/2016. You purchased 20 units at a price of $600.\n",
      "exit\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import openai\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "class CacheStack:\n",
    "    \n",
    "    def __init__(self, max_size, item_length):\n",
    "        self.stack = []\n",
    "        self.max_size = max_size\n",
    "        self.item_length = item_length\n",
    "    \n",
    "    def push(self, item):\n",
    "        if len(self.stack) >= self.max_size:\n",
    "            self.stack.pop()\n",
    "        if len(item) > self.item_length:\n",
    "            item = item[:self.item_length]\n",
    "        self.stack.insert(0, item)\n",
    "\n",
    "    \n",
    "    def pop(self):\n",
    "        if len(self.stack) == 0:\n",
    "            raise Exception(\"Stack is empty\")\n",
    "        return self.stack.pop(self.max_size - 1)\n",
    "    \n",
    "    def is_empty(self):\n",
    "        return len(self.stack) == 0\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self.stack)\n",
    "    \n",
    "    def peek(self):\n",
    "        if len(self.stack) == 0:\n",
    "            raise Exception(\"Stack is empty\")\n",
    "        return self.stack[0]\n",
    "\n",
    "    def convert_list_to_json(self):\n",
    "        res = {\"context\": [item for item in self.stack]}\n",
    "        return json.dumps(res)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function query GPT-4\n",
    "def get_responde_from_gpt4(sys, usr, assist, tmp=0):\n",
    "    response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\", # The deployment name you chose when you deployed the ChatGPT or GPT-4 model.\n",
    "    #model=\"gpt-3.5-turbo\",\n",
    "    temperature = tmp,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": sys},\n",
    "        {\"role\": \"user\", \"content\": usr},\n",
    "        {\"role\": \"assistant\", \"content\": assist}\n",
    "    ])\n",
    "    res = (response['choices'][0]['message']['content'])\n",
    "    return res\n",
    "\n",
    "\n",
    "# Function to determine if the query is out of the scope of this app\n",
    "def is_a_valid_qry(qry):\n",
    "    sys = \"You are a helpful assistant that will stop queries not related to the scope of this app.\"\n",
    "    usr = \"\"\"\n",
    "    This app can answer questions related to historic data containing dates, \n",
    "    products, quantities, and prices. All questions that can be answered using\n",
    "    this type of data like querying for products, suggesting products based on \n",
    "    former buys, etc. are valid.\n",
    "    Answer yes if the following question is within the scope of the application, otherwise answer no.\n",
    "    Place the yes or no at the beginning of your response please.\n",
    "\n",
    "    \"\"\"\n",
    "    assist = qry\n",
    "    res = get_responde_from_gpt4(sys, usr, assist)\n",
    "    return res\n",
    "        \n",
    "\"\"\" Function to determine which days the query might be referred to. This is\n",
    "required to be able to extract the required data from the database.\n",
    "\"\"\"\n",
    "def dates_to_be_included_to_answer_the_query(qry, cur_date, cach):\n",
    "    sys = \"You are an helpful assitant that will deduce the dates that this query is refering to.\"\n",
    "    usr = \"\"\"\n",
    "    If the last purchase date is \"\"\" + cur_date\n",
    "    if len(cach) == 0 :\n",
    "        usr = usr + \"\"\"\n",
    "         \n",
    "        Which dates can be included in the following query. \n",
    "        Answer me in the following format: \n",
    "        {\n",
    "        \"start_date\": \"?\",\n",
    "        \"end_date\": \"?\"\n",
    "        } \n",
    "        If no date is specified respond with end_date equal to last purchase\n",
    "        date and start_date equals 6 month before.\n",
    "        If the dates can be determine do not include any explanation just the data in the specified JSON format.\n",
    "        \"\"\"\n",
    "    else:\n",
    "        usr = usr + cach +  \"\"\"\n",
    "         \n",
    "        Which dates can be included in the following query. \n",
    "        Answer me in the following format: \n",
    "        {\n",
    "        \"start_date\": \"?\",\n",
    "        \"end_date\": \"?\"\n",
    "        } \n",
    "        If no date is specified respond with end_date equal to last purchase\n",
    "        date and start_date equals 6 month before.\n",
    "        If the dates can be determine do not include any explanation just the data in the specified JSON format.\n",
    "        \"\"\"\n",
    "    assist = \"query: \" + qry\n",
    "    res = get_responde_from_gpt4(sys, usr, assist)\n",
    "    return res\n",
    "\n",
    "\n",
    "# Function that actually execute the query.\n",
    "\n",
    "def get_answer_from_query(qry, json_context):\n",
    "    sys = \"You are an helpful assitant that can answer queries about my purchages including sugestions.\"\n",
    "    usr = \"To answer the question use the following data: \" + json_context + \"\"\"\n",
    "     \"\"\"\n",
    "    assist = \"query: \" + qry\n",
    "    res = get_responde_from_gpt4(sys, usr, assist, tmp= 0.5)\n",
    "    return res\n",
    "\n",
    "openai.api_key = \"\"\n",
    "myStack = CacheStack(4, 1024)\n",
    "\n",
    "emb_dat = pd.read_csv(\"data/sales_data_emb.csv\")\n",
    "current_date = emb_dat.iloc[-1]['dates']\n",
    "while True:\n",
    "# Prompt the user for a question\n",
    "    question = input(\"What is your question? \")\n",
    "    print(question)\n",
    "\n",
    "    #If the user enters 'exit', break out of the loop\n",
    "    if question == 'exit':\n",
    "        break\n",
    "    \n",
    "    # Process the question and generate an answer\n",
    "    # Is this a valid question?\n",
    "    res = is_a_valid_qry(question)\n",
    "    yes = \"Yes\".upper()\n",
    "    if 3 > len(res) or res[:3].upper() != yes: # if is not yes then the question is not compatible with the app\n",
    "        print(res)\n",
    "        time.sleep(3)\n",
    "        continue\n",
    "    \n",
    "    cach = myStack.convert_list_to_json()\n",
    "    answer = dates_to_be_included_to_answer_the_query(question, current_date, cach)\n",
    "    try:\n",
    "        data = json.loads(answer)\n",
    "        start_date = data['start_date']\n",
    "        end_date = data['end_date']\n",
    "        # Cache answer\n",
    "        myStack.push(answer)\n",
    "    except:\n",
    "        input_date = datetime.strptime(current_date, \"%m/%d/%Y\")\n",
    "        # Calculate the date that is 6 months before the input date\n",
    "        six_months_before = input_date - timedelta(days=6*30)\n",
    "        # Convert the result back to a string\n",
    "        end_date = current_date\n",
    "        start_date = six_months_before.strftime(\"%m/%d/%Y\") \n",
    "\n",
    "    current_date_products = emb_dat.iloc[-1]['products']\n",
    "\n",
    "    start_datetime = datetime.strptime(start_date, '%m/%d/%Y').date()\n",
    "    end_datetime = datetime.strptime(end_date, '%m/%d/%Y').date()\n",
    "    all_products_json = {}\n",
    "    for index, row in emb_dat.iterrows():\n",
    "        row_date = datetime.strptime(row['dates'], '%m/%d/%Y').date()\n",
    "        if start_datetime <= row_date <= end_datetime:\n",
    "            dict_prod = json.loads(row['products'])\n",
    "            all_products_json.update(dict_prod)\n",
    "            \n",
    "# Display the answer\n",
    "    json_products_concatenated = json.dumps(all_products_json)\n",
    "    json_products_concatenated = cach + \" \" + json_products_concatenated\n",
    "    answer = get_answer_from_query(question, json_products_concatenated)\n",
    "    print(answer)\n",
    "    prompt_response = \"question:\" + question + \" answer: \" + answer\n",
    "    myStack.push(prompt_response)\n",
    "    time.sleep(3) \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
